{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:21:15.113699Z",
     "iopub.status.busy": "2021-05-30T17:21:15.113476Z",
     "iopub.status.idle": "2021-05-30T17:21:20.777506Z",
     "shell.execute_reply": "2021-05-30T17:21:20.775896Z",
     "shell.execute_reply.started": "2021-05-30T17:21:15.113670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting cnn_finetune\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e4/63/03a442d31401c43fc17a814f22bd7c39ab8f13f42a6b2467ca0d0d042b3a/cnn_finetune-0.6.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/site-packages (from cnn_finetune) (1.6.0+cu101)\n",
      "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/site-packages (from cnn_finetune) (0.7.0+cu101)\n",
      "Collecting pretrainedmodels>=0.7.4\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 1.2 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/site-packages (from cnn_finetune) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from cnn_finetune) (4.59.0)\n",
      "Collecting munch\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/site-packages (from torchvision>=0.3.0->cnn_finetune) (6.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from torchvision>=0.3.0->cnn_finetune) (1.19.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/site-packages (from torch->cnn_finetune) (0.18.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from munch->pretrainedmodels>=0.7.4->cnn_finetune) (1.15.0)\n",
      "Building wheels for collected packages: cnn-finetune, pretrainedmodels\n",
      "  Building wheel for cnn-finetune (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cnn-finetune: filename=cnn_finetune-0.6.0-py3-none-any.whl size=11429 sha256=ebb11741295dd549fe0ba00e0ac5e34ac075bf7945eb5e38b8159186ed24738a\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/f1/77/89f6aa0db08b6ed8d439515e656ef857f85b5134e8e122a28b\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60963 sha256=7a62555c5771916463b00319aa059f53164943086fa144d2252f085e0ca45c6d\n",
      "  Stored in directory: /root/.cache/pip/wheels/5d/67/54/9988bfb941caec18053c1e2d6bb958b4aca98a6764018ea7c4\n",
      "Successfully built cnn-finetune pretrainedmodels\n",
      "Installing collected packages: munch, pretrainedmodels, cnn-finetune\n",
      "Successfully installed cnn-finetune-0.6.0 munch-2.5.0 pretrainedmodels-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install cnn_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:21:23.816632Z",
     "iopub.status.busy": "2021-05-30T17:21:23.816062Z",
     "iopub.status.idle": "2021-05-30T17:21:24.334637Z",
     "shell.execute_reply": "2021-05-30T17:21:24.333659Z",
     "shell.execute_reply.started": "2021-05-30T17:21:23.816571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 331)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_label=pd.read_csv('../input/fu-data/data/train_label.csv')\n",
    "len(train_label[train_label['label']==1.0]),len(train_label[train_label['label']==0.0]) #可见正负样本十分均衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:21:56.388050Z",
     "iopub.status.busy": "2021-05-30T17:21:56.387112Z",
     "iopub.status.idle": "2021-05-30T17:21:56.399164Z",
     "shell.execute_reply": "2021-05-30T17:21:56.398075Z",
     "shell.execute_reply.started": "2021-05-30T17:21:56.387980Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    backbone = 'xception'#\n",
    "    num_classes = 2 #\n",
    "    use_smooth_label=False\n",
    "    loss = 'CrossEntropyLoss'#focal_loss/CrossEntropyLoss\n",
    "    input_size = 384\n",
    "    train_batch_size = 16  # batch size\n",
    "    val_batch_size = 12\n",
    "    test_batch_size = 1\n",
    "    optimizer = 'adam'#sam/adam\n",
    "    lr_scheduler='exp'#cosine/exp/poly\n",
    "    lr = 3e-4  # adam 0.00001\n",
    "    sam_lr=1e-3\n",
    "    MOMENTUM = 0.9\n",
    "    device = \"cuda\"  # cuda  or cpu\n",
    "    gpu_id = [0]\n",
    "    num_workers = 8  # how many workers for loading data\n",
    "    max_epoch = 21\n",
    "    weight_decay = 5e-4\n",
    "    val_interval = 1\n",
    "    print_interval = 50\n",
    "    save_interval = 2\n",
    "    tensorboard_interval=50\n",
    "    min_save_epoch=1\n",
    "    load_from = None\n",
    "    #\n",
    "    log_dir = 'log/'\n",
    "    train_val_data = '../input/fu-data/data/train/'\n",
    "    train_label_csv = '../input/fu-data/data/train_label.csv'\n",
    "    #\n",
    "    checkpoints_dir = './ckpt/'\n",
    "    pre_trained = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:22:40.892742Z",
     "iopub.status.busy": "2021-05-30T17:22:40.892173Z",
     "iopub.status.idle": "2021-05-30T17:22:47.093838Z",
     "shell.execute_reply": "2021-05-30T17:22:47.092379Z",
     "shell.execute_reply.started": "2021-05-30T17:22:40.892682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torchtoolbox\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a2/b3/720399783618f307c6b1cac4d2507602514720df66f26ccb57319a75d9e1/torchtoolbox-0.1.5-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 8.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting lmdb\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4d/48/8b040e5120c3dc1bdd85d26e5301336a2185756567c9fe449fbf681c0936/lmdb-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 43.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from torchtoolbox) (4.59.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/site-packages (from torchtoolbox) (0.24.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/site-packages (from torchtoolbox) (4.1.1.100)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from torchtoolbox) (1.15.0)\n",
      "Collecting pyarrow\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/da/a4/f06bed88d461ea82c9c4e4c244ce76ec96b0cd960aeee5f4eb5f84fc05cc/pyarrow-4.0.1-cp36-cp36m-manylinux2014_x86_64.whl (21.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.9 MB 5.4 MB/s eta 0:00:011     |███████████████████▎            | 13.2 MB 42.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/site-packages (from torchtoolbox) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from torchtoolbox) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/site-packages (from scikit-learn->torchtoolbox) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/site-packages (from scikit-learn->torchtoolbox) (2.1.0)\n",
      "Installing collected packages: pyarrow, lmdb, torchtoolbox\n",
      "Successfully installed lmdb-1.2.1 pyarrow-4.0.1 torchtoolbox-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtoolbox -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:23:25.997636Z",
     "iopub.status.busy": "2021-05-30T17:23:25.997178Z",
     "iopub.status.idle": "2021-05-30T17:23:26.662860Z",
     "shell.execute_reply": "2021-05-30T17:23:26.661981Z",
     "shell.execute_reply.started": "2021-05-30T17:23:25.997591Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "import cv2\n",
    "from PIL import ImageFile\n",
    "from torchtoolbox.transform import Cutout\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class fuDataset(Dataset):\n",
    "    def __init__(self, root, train_label_csv, phase='train', input_size=224):\n",
    "        self.phase = phase\n",
    "        train_val_label=pd.read_csv('../input/fu-data/data/train_label.csv')\n",
    "        val_ids=[i for i in range(len(train_label)) if i%5==0]#验证集\n",
    "        train_ids=[i for i in range(len(train_label)) if i%5!=0]#训练集\n",
    "        if phase=='train':\n",
    "            img_label=train_val_label[train_val_label.index.isin(train_ids)].reset_index()\n",
    "            self.img_names=[os.path.join(root,i) for i in img_label['img_id'].values]\n",
    "            self.labels=img_label['label'].values\n",
    "        else:\n",
    "            img_label=train_val_label[train_val_label.index.isin(val_ids)].reset_index()\n",
    "            self.img_names=[os.path.join(root,i) for i in img_label['img_id'].values]\n",
    "            self.labels=img_label['label'].values\n",
    "        #使用全部数据训练（不要验证集）\n",
    "        self.img_names=[os.path.join(root,i) for i in train_val_label['img_id'].values]\n",
    "        self.labels=train_val_label['label'].values\n",
    "        #\n",
    "        normalize = T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        if self.phase == 'train':\n",
    "            self.transforms = T.Compose([\n",
    "                T.Resize((input_size,input_size)),\n",
    "                Cutout(),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "                T.RandomVerticalFlip(p=0.25),\n",
    "                T.RandomRotation(degrees=(-20,20)),\n",
    "                T.ColorJitter(0.2,0.2),\n",
    "                T.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = T.Compose([\n",
    "                T.Resize((input_size,input_size)),\n",
    "                T.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_names[index]\n",
    "        data = Image.open(img_path)\n",
    "        data = data.convert('RGB')\n",
    "        data = self.transforms(data)\n",
    "        label = np.int32(self.labels[index])\n",
    "        return data.float(), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:23:29.843984Z",
     "iopub.status.busy": "2021-05-30T17:23:29.843480Z",
     "iopub.status.idle": "2021-05-30T17:23:29.855120Z",
     "shell.execute_reply": "2021-05-30T17:23:29.853983Z",
     "shell.execute_reply.started": "2021-05-30T17:23:29.843932Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_logger(filename, verbosity=1, name=None):\n",
    "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s][%(filename)s][%(levelname)s] %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level_dict[verbosity])\n",
    "\n",
    "    fh = logging.FileHandler(filename, \"w\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:23:53.089725Z",
     "iopub.status.busy": "2021-05-30T17:23:53.089149Z",
     "iopub.status.idle": "2021-05-30T17:24:00.986000Z",
     "shell.execute_reply": "2021-05-30T17:24:00.984322Z",
     "shell.execute_reply.started": "2021-05-30T17:23:53.089663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting tensorboardX\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from tensorboardX) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/site-packages (from tensorboardX) (3.15.6)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:24:33.363887Z",
     "iopub.status.busy": "2021-05-30T17:24:33.363379Z",
     "iopub.status.idle": "2021-05-30T17:24:34.476774Z",
     "shell.execute_reply": "2021-05-30T17:24:34.475612Z",
     "shell.execute_reply.started": "2021-05-30T17:24:33.363832Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "from cnn_finetune import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-05-30T17:25:50.589018Z",
     "iopub.status.busy": "2021-05-30T17:25:50.588434Z",
     "iopub.status.idle": "2021-05-30T17:38:40.987171Z",
     "shell.execute_reply": "2021-05-30T17:38:40.985783Z",
     "shell.execute_reply.started": "2021-05-30T17:25:50.588956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-30 17:25:50,631][<ipython-input-10-23f9ae6e6884>][INFO] Using: xception\n",
      "[2021-05-30 17:25:50,632][<ipython-input-10-23f9ae6e6884>][INFO] InputSize: 384\n",
      "[2021-05-30 17:25:50,633][<ipython-input-10-23f9ae6e6884>][INFO] optimizer: adam\n",
      "[2021-05-30 17:25:50,634][<ipython-input-10-23f9ae6e6884>][INFO] lr_init: 0.0003\n",
      "[2021-05-30 17:25:50,636][<ipython-input-10-23f9ae6e6884>][INFO] batch size: 16\n",
      "[2021-05-30 17:25:50,637][<ipython-input-10-23f9ae6e6884>][INFO] criterion: CrossEntropyLoss\n",
      "[2021-05-30 17:25:50,638][<ipython-input-10-23f9ae6e6884>][INFO] Using label smooth: False\n",
      "[2021-05-30 17:25:50,640][<ipython-input-10-23f9ae6e6884>][INFO] lr_scheduler: exp\n",
      "[2021-05-30 17:25:50,641][<ipython-input-10-23f9ae6e6884>][INFO] Using the GPU: [0]\n",
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/xception-43020ad28.pth\" to /output/.torch/hub/checkpoints/xception-43020ad28.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92816ab16e66442cbefb4739bf208ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/87.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-30 17:30:16,210][<ipython-input-10-23f9ae6e6884>][INFO] total_iters:46\n",
      "[2021-05-30 17:30:16,215][<ipython-input-10-23f9ae6e6884>][INFO] start training...\n",
      "[2021-05-30 17:30:16,218][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.0003\n",
      "[2021-05-30 17:30:16,219][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 1/21\n",
      "[2021-05-30 17:30:16,220][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:30:18,274][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:1(1/46) loss:0.856 lr:0.0002223 epoch_Time:1.0min:\n",
      "[2021-05-30 17:30:33,771][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:1(46/46) loss:0.900 lr:0.0000758 epoch_Time:0.0min:\n",
      "[2021-05-30 17:30:39,764][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.2741 valAcc: 0.9001\n",
      "[2021-05-30 17:30:39,769][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[1/21] train_acc=0.701 \n",
      "[2021-05-30 17:30:39,983][<ipython-input-10-23f9ae6e6884>][INFO] save best epoch: 1 best acc: 0.9001386962552012\n",
      "[2021-05-30 17:30:39,985][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:7.575000000000001e-05\n",
      "[2021-05-30 17:30:39,986][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 2/21\n",
      "[2021-05-30 17:30:39,987][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:30:41,563][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:2(1/46) loss:0.367 lr:0.0000728 epoch_Time:1.0min:\n",
      "[2021-05-30 17:30:57,200][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:2(46/46) loss:0.788 lr:0.0003000 epoch_Time:0.0min:\n",
      "[2021-05-30 17:31:03,359][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.2249 valAcc: 0.9182\n",
      "[2021-05-30 17:31:03,363][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[2/21] train_acc=0.833 \n",
      "[2021-05-30 17:31:03,733][<ipython-input-10-23f9ae6e6884>][INFO] save best epoch: 2 best acc: 0.9181692094313454\n",
      "[2021-05-30 17:31:03,907][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.0003\n",
      "[2021-05-30 17:31:03,908][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 3/21\n",
      "[2021-05-30 17:31:03,909][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:31:05,557][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:3(1/46) loss:0.215 lr:0.0003000 epoch_Time:1.0min:\n",
      "[2021-05-30 17:31:21,340][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:3(46/46) loss:0.838 lr:0.0002800 epoch_Time:0.0min:\n",
      "[2021-05-30 17:31:27,403][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.1446 valAcc: 0.9431\n",
      "[2021-05-30 17:31:27,404][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[3/21] train_acc=0.807 \n",
      "[2021-05-30 17:31:27,739][<ipython-input-10-23f9ae6e6884>][INFO] save best epoch: 3 best acc: 0.9431345353675451\n",
      "[2021-05-30 17:31:27,744][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.0002799707978657736\n",
      "[2021-05-30 17:31:27,745][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 4/21\n",
      "[2021-05-30 17:31:27,746][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:31:29,457][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:4(1/46) loss:0.366 lr:0.0002791 epoch_Time:1.0min:\n",
      "[2021-05-30 17:31:45,275][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:4(46/46) loss:0.526 lr:0.0002252 epoch_Time:0.0min:\n",
      "[2021-05-30 17:31:51,260][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.1918 valAcc: 0.9168\n",
      "[2021-05-30 17:31:51,262][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[4/21] train_acc=0.853 \n",
      "[2021-05-30 17:31:51,541][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.00022524999999999995\n",
      "[2021-05-30 17:31:51,542][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 5/21\n",
      "[2021-05-30 17:31:51,543][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:31:53,260][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:5(1/46) loss:0.163 lr:0.0002238 epoch_Time:1.0min:\n",
      "[2021-05-30 17:32:09,097][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:5(46/46) loss:1.290 lr:0.0001505 epoch_Time:0.0min:\n",
      "[2021-05-30 17:32:14,997][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0728 valAcc: 0.9681\n",
      "[2021-05-30 17:32:15,000][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[5/21] train_acc=0.876 \n",
      "[2021-05-30 17:32:15,338][<ipython-input-10-23f9ae6e6884>][INFO] save best epoch: 5 best acc: 0.9680998613037448\n",
      "[2021-05-30 17:32:15,342][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.00015049999999999997\n",
      "[2021-05-30 17:32:15,343][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 6/21\n",
      "[2021-05-30 17:32:15,344][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:32:16,958][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:6(1/46) loss:0.299 lr:0.0001488 epoch_Time:1.0min:\n",
      "[2021-05-30 17:32:32,900][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:6(46/46) loss:0.417 lr:0.0000758 epoch_Time:0.0min:\n",
      "[2021-05-30 17:32:38,893][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0245 valAcc: 0.9945\n",
      "[2021-05-30 17:32:38,895][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[6/21] train_acc=0.928 \n",
      "[2021-05-30 17:32:39,206][<ipython-input-10-23f9ae6e6884>][INFO] save best epoch: 6 best acc: 0.9944521497919556\n",
      "[2021-05-30 17:32:39,376][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:7.575000000000001e-05\n",
      "[2021-05-30 17:32:39,377][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 7/21\n",
      "[2021-05-30 17:32:39,378][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:32:40,959][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:7(1/46) loss:0.088 lr:0.0000743 epoch_Time:1.0min:\n",
      "[2021-05-30 17:32:56,985][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:7(46/46) loss:0.446 lr:0.0000210 epoch_Time:0.0min:\n",
      "[2021-05-30 17:33:02,981][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0209 valAcc: 0.9931\n",
      "[2021-05-30 17:33:02,983][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[7/21] train_acc=0.925 \n",
      "[2021-05-30 17:33:02,986][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:2.102920213422641e-05\n",
      "[2021-05-30 17:33:02,987][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 8/21\n",
      "[2021-05-30 17:33:02,988][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:33:04,558][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:8(1/46) loss:0.048 lr:0.0000202 epoch_Time:1.0min:\n",
      "[2021-05-30 17:33:20,722][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:8(46/46) loss:0.395 lr:0.0003000 epoch_Time:0.0min:\n",
      "[2021-05-30 17:33:26,787][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0210 valAcc: 0.9972\n",
      "[2021-05-30 17:33:26,789][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[8/21] train_acc=0.955 \n",
      "[2021-05-30 17:33:27,230][<ipython-input-10-23f9ae6e6884>][INFO] save best epoch: 8 best acc: 0.9972260748959778\n",
      "[2021-05-30 17:33:27,421][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.0003\n",
      "[2021-05-30 17:33:27,422][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 9/21\n",
      "[2021-05-30 17:33:27,423][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:33:29,055][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:9(1/46) loss:0.016 lr:0.0003000 epoch_Time:1.0min:\n",
      "[2021-05-30 17:33:45,162][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:9(46/46) loss:1.355 lr:0.0002949 epoch_Time:0.0min:\n",
      "[2021-05-30 17:33:51,191][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 1.0473 valAcc: 0.8516\n",
      "[2021-05-30 17:33:51,193][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[9/21] train_acc=0.929 \n",
      "[2021-05-30 17:33:51,196][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.00029490591103021566\n",
      "[2021-05-30 17:33:51,197][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 10/21\n",
      "[2021-05-30 17:33:51,198][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:33:52,658][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:10(1/46) loss:0.171 lr:0.0002947 epoch_Time:1.0min:\n",
      "[2021-05-30 17:34:08,809][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:10(46/46) loss:0.262 lr:0.0002800 epoch_Time:0.0min:\n",
      "[2021-05-30 17:34:15,015][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.3088 valAcc: 0.8821\n",
      "[2021-05-30 17:34:15,018][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[10/21] train_acc=0.875 \n",
      "[2021-05-30 17:34:15,264][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.0002799707978657736\n",
      "[2021-05-30 17:34:15,265][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 11/21\n",
      "[2021-05-30 17:34:15,266][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:34:16,959][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:11(1/46) loss:0.111 lr:0.0002795 epoch_Time:1.0min:\n",
      "[2021-05-30 17:34:33,098][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:11(46/46) loss:0.665 lr:0.0002562 epoch_Time:0.0min:\n",
      "[2021-05-30 17:34:39,191][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0296 valAcc: 0.9931\n",
      "[2021-05-30 17:34:39,194][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[11/21] train_acc=0.904 \n",
      "[2021-05-30 17:34:39,196][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.00025621246378738883\n",
      "[2021-05-30 17:34:39,197][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 12/21\n",
      "[2021-05-30 17:34:39,197][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:34:40,858][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:12(1/46) loss:0.104 lr:0.0002556 epoch_Time:1.0min:\n",
      "[2021-05-30 17:34:57,140][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:12(46/46) loss:0.224 lr:0.0002252 epoch_Time:0.0min:\n",
      "[2021-05-30 17:35:03,208][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0157 valAcc: 0.9958\n",
      "[2021-05-30 17:35:03,211][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[12/21] train_acc=0.918 \n",
      "[2021-05-30 17:35:03,440][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.00022524999999999995\n",
      "[2021-05-30 17:35:03,441][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 13/21\n",
      "[2021-05-30 17:35:03,442][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:35:05,056][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:13(1/46) loss:0.015 lr:0.0002245 epoch_Time:1.0min:\n",
      "[2021-05-30 17:35:21,203][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:13(46/46) loss:0.968 lr:0.0001892 epoch_Time:0.0min:\n",
      "[2021-05-30 17:35:27,459][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0218 valAcc: 0.9945\n",
      "[2021-05-30 17:35:27,463][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[13/21] train_acc=0.931 \n",
      "[2021-05-30 17:35:27,465][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.00018919344724282683\n",
      "[2021-05-30 17:35:27,466][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 14/21\n",
      "[2021-05-30 17:35:27,467][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:35:29,157][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:14(1/46) loss:0.018 lr:0.0001884 epoch_Time:1.0min:\n",
      "[2021-05-30 17:35:45,366][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:14(46/46) loss:1.169 lr:0.0001505 epoch_Time:0.0min:\n",
      "[2021-05-30 17:35:51,594][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0134 valAcc: 0.9958\n",
      "[2021-05-30 17:35:51,596][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[14/21] train_acc=0.938 \n",
      "[2021-05-30 17:35:51,802][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.00015049999999999997\n",
      "[2021-05-30 17:35:51,803][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 15/21\n",
      "[2021-05-30 17:35:51,804][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:35:53,360][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:15(1/46) loss:0.013 lr:0.0001496 epoch_Time:1.0min:\n",
      "[2021-05-30 17:36:09,644][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:15(46/46) loss:0.794 lr:0.0001118 epoch_Time:0.0min:\n",
      "[2021-05-30 17:36:15,764][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0041 valAcc: 1.0000\n",
      "[2021-05-30 17:36:15,767][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[15/21] train_acc=0.940 \n",
      "[2021-05-30 17:36:16,126][<ipython-input-10-23f9ae6e6884>][INFO] save best epoch: 15 best acc: 1.0\n",
      "[2021-05-30 17:36:16,130][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.00011180655275717314\n",
      "[2021-05-30 17:36:16,132][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 16/21\n",
      "[2021-05-30 17:36:16,133][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:36:17,858][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:16(1/46) loss:0.003 lr:0.0001110 epoch_Time:1.0min:\n",
      "[2021-05-30 17:36:34,137][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:16(46/46) loss:1.122 lr:0.0000758 epoch_Time:0.0min:\n",
      "[2021-05-30 17:36:40,468][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0135 valAcc: 0.9945\n",
      "[2021-05-30 17:36:40,471][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[16/21] train_acc=0.939 \n",
      "[2021-05-30 17:36:40,680][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:7.575000000000001e-05\n",
      "[2021-05-30 17:36:40,681][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 17/21\n",
      "[2021-05-30 17:36:40,682][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:36:42,259][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:17(1/46) loss:0.025 lr:0.0000750 epoch_Time:1.0min:\n",
      "[2021-05-30 17:36:58,513][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:17(46/46) loss:0.710 lr:0.0000448 epoch_Time:0.0min:\n",
      "[2021-05-30 17:37:04,662][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0027 valAcc: 1.0000\n",
      "[2021-05-30 17:37:04,665][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[17/21] train_acc=0.966 \n",
      "[2021-05-30 17:37:04,668][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:4.478753621261114e-05\n",
      "[2021-05-30 17:37:04,670][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 18/21\n",
      "[2021-05-30 17:37:04,670][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:37:06,262][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:18(1/46) loss:0.003 lr:0.0000442 epoch_Time:1.0min:\n",
      "[2021-05-30 17:37:22,473][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:18(46/46) loss:0.531 lr:0.0000210 epoch_Time:0.0min:\n",
      "[2021-05-30 17:37:28,673][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0016 valAcc: 1.0000\n",
      "[2021-05-30 17:37:28,676][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[18/21] train_acc=0.970 \n",
      "[2021-05-30 17:37:28,844][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:2.102920213422641e-05\n",
      "[2021-05-30 17:37:28,845][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 19/21\n",
      "[2021-05-30 17:37:28,846][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:37:30,392][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:19(1/46) loss:0.026 lr:0.0000206 epoch_Time:1.0min:\n",
      "[2021-05-30 17:37:46,635][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:19(46/46) loss:0.529 lr:0.0000061 epoch_Time:0.0min:\n",
      "[2021-05-30 17:37:52,865][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0012 valAcc: 1.0000\n",
      "[2021-05-30 17:37:52,869][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[19/21] train_acc=0.961 \n",
      "[2021-05-30 17:37:52,871][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:6.0940889697843025e-06\n",
      "[2021-05-30 17:37:52,872][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 20/21\n",
      "[2021-05-30 17:37:52,873][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:37:54,458][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:20(1/46) loss:0.001 lr:0.0000059 epoch_Time:1.0min:\n",
      "[2021-05-30 17:38:10,654][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:20(46/46) loss:0.901 lr:0.0003000 epoch_Time:0.0min:\n",
      "[2021-05-30 17:38:16,857][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.0016 valAcc: 1.0000\n",
      "[2021-05-30 17:38:16,859][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[20/21] train_acc=0.965 \n",
      "[2021-05-30 17:38:17,067][<ipython-input-10-23f9ae6e6884>][INFO] learning rate:0.0003\n",
      "[2021-05-30 17:38:17,068][<ipython-input-10-23f9ae6e6884>][INFO] Epoch 21/21\n",
      "[2021-05-30 17:38:17,069][<ipython-input-10-23f9ae6e6884>][INFO] ----------\n",
      "[2021-05-30 17:38:18,656][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:21(1/46) loss:0.400 lr:0.0003000 epoch_Time:1.0min:\n",
      "[2021-05-30 17:38:34,839][<ipython-input-10-23f9ae6e6884>][INFO]  Epoch:21(46/46) loss:1.034 lr:0.0002987 epoch_Time:0.0min:\n",
      "[2021-05-30 17:38:40,971][<ipython-input-10-23f9ae6e6884>][INFO] valLoss: 0.1607 valAcc: 0.9445\n",
      "[2021-05-30 17:38:40,975][<ipython-input-10-23f9ae6e6884>][INFO] Epoch:[21/21] train_acc=0.921 \n",
      "[2021-05-30 17:38:40,976][<ipython-input-10-23f9ae6e6884>][INFO] Best acc: 1.000 Best epoch:15\n",
      "[2021-05-30 17:38:40,977][<ipython-input-10-23f9ae6e6884>][INFO] Training complete in 8m 25s\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def train_model(model,criterion, optimizer, lr_scheduler=None):\n",
    "\n",
    "    train_dataset = fuDataset(opt.train_val_data, opt.train_label_csv, phase='train', input_size=opt.input_size)\n",
    "    trainloader = DataLoader(train_dataset,\n",
    "                             batch_size=opt.train_batch_size,\n",
    "                             shuffle=True,\n",
    "                             num_workers=opt.num_workers)\n",
    "\n",
    "    total_iters=len(trainloader)\n",
    "    logger.info('total_iters:{}'.format(total_iters))\n",
    "    model_name=opt.backbone\n",
    "    since = time.time()\n",
    "    best_score = 0.0\n",
    "    best_epoch = 0\n",
    "    log_acc=0\n",
    "    log_train=0\n",
    "    writer = SummaryWriter()  # 用于记录训练和测试的信息:loss,acc等\n",
    "    logger.info('start training...')\n",
    "    #\n",
    "    iters = len(trainloader)\n",
    "    for epoch in range(1,opt.max_epoch+1):\n",
    "        model.train(True)\n",
    "        begin_time=time.time()\n",
    "        logger.info('learning rate:{}'.format(optimizer.param_groups[-1]['lr']))\n",
    "        logger.info('Epoch {}/{}'.format(epoch, opt.max_epoch))\n",
    "        logger.info('-' * 10)\n",
    "        running_corrects_linear = 0\n",
    "        count=0\n",
    "        train_loss = []\n",
    "        for i, data in enumerate(trainloader):\n",
    "            count+=1\n",
    "            inputs, labels = data\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            #\n",
    "            out_linear= model(inputs)\n",
    "            _, linear_preds = torch.max(out_linear.data, 1)\n",
    "            loss = criterion(out_linear, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 更新cosine学习率\n",
    "            lr_scheduler.step(epoch + count / iters)\n",
    "\n",
    "            if i % opt.print_interval == 0 or out_linear.size()[0] < opt.train_batch_size:\n",
    "                spend_time = time.time() - begin_time\n",
    "                logger.info(\n",
    "                    ' Epoch:{}({}/{}) loss:{:.3f} lr:{:.7f} epoch_Time:{}min:'.format(\n",
    "                        epoch, count, total_iters,\n",
    "                        loss.item(), optimizer.param_groups[-1]['lr'],\n",
    "                        spend_time / count * total_iters // 60 - spend_time // 60))\n",
    "            #\n",
    "            running_corrects_linear += torch.sum(linear_preds == labels.data)\n",
    "            train_loss.append(loss.item())\n",
    "            writer.add_scalar('train_loss',loss.item(), global_step=log_train)\n",
    "            log_train+=1\n",
    "            #\n",
    "        #lr_scheduler.step()\n",
    "        val_acc,val_loss= val_model(model, criterion)\n",
    "        epoch_acc_linear = running_corrects_linear.double() / total_iters / opt.train_batch_size\n",
    "        logger.info('valLoss: {:.4f} valAcc: {:.4f}'.format(val_loss,val_acc))\n",
    "        logger.info('Epoch:[{}/{}] train_acc={:.3f} '.format(epoch, opt.max_epoch,\n",
    "                                                                    epoch_acc_linear))\n",
    "        #\n",
    "        model_out_path = model_save_dir + \"/\" + '{}_'.format(model_name) + str(epoch) + '.pth'\n",
    "        best_model_out_path = model_save_dir + \"/\" + '{}_'.format(model_name) + 'best' + '.pth'\n",
    "        #model_out_path = '{}_'.format(model_name) + str(epoch) + '.pth'\n",
    "        #save the best model\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_epoch=epoch\n",
    "            torch.save(model.state_dict(), best_model_out_path)\n",
    "            logger.info(\"save best epoch: {} best acc: {}\".format(best_epoch,val_acc))\n",
    "        #save based on epoch interval\n",
    "        if epoch % opt.save_interval == 0 and epoch>opt.min_save_epoch:\n",
    "            torch.save(model.state_dict(), model_out_path)\n",
    "    #\n",
    "    logger.info('Best acc: {:.3f} Best epoch:{}'.format(best_score,best_epoch))\n",
    "    time_elapsed = time.time() - since\n",
    "    logger.info('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    writer.close()\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_model(model, criterion):\n",
    "    val_dataset = fuDataset(opt.train_val_data, opt.train_label_csv, phase='val', input_size=opt.input_size)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                             batch_size=opt.val_batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=opt.num_workers)\n",
    "    dset_sizes=len(val_dataset)\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    pres_list=[]\n",
    "    labels_list=[]\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if cont == 0:\n",
    "            outPre = outputs.data.cpu()\n",
    "            outLabel = labels.data.cpu()\n",
    "        else:\n",
    "            outPre = torch.cat((outPre, outputs.data.cpu()), 0)\n",
    "            outLabel = torch.cat((outLabel, labels.data.cpu()), 0)\n",
    "        pres_list+=preds.cpu().numpy().tolist()\n",
    "        labels_list+=labels.data.cpu().numpy().tolist()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        cont += 1\n",
    "    #\n",
    "    val_acc = accuracy_score(labels_list, pres_list)\n",
    "    return val_acc,running_loss / dset_sizes\n",
    "\n",
    "#\n",
    "if __name__ == \"__main__\":\n",
    "    #\n",
    "    opt = Config()\n",
    "    torch.cuda.empty_cache()\n",
    "    device = torch.device(opt.device)\n",
    "    criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "    model_name=opt.backbone\n",
    "    model_save_dir =os.path.join(opt.checkpoints_dir , model_name)\n",
    "    if not os.path.exists(model_save_dir): os.makedirs(model_save_dir)\n",
    "    logger = get_logger(os.path.join(model_save_dir,'log.log'))\n",
    "    logger.info('Using: {}'.format(model_name))\n",
    "    logger.info('InputSize: {}'.format(opt.input_size))\n",
    "    logger.info('optimizer: {}'.format(opt.optimizer))\n",
    "    logger.info('lr_init: {}'.format(opt.lr))\n",
    "    logger.info('batch size: {}'.format(opt.train_batch_size))\n",
    "    logger.info('criterion: {}'.format(opt.loss))\n",
    "    logger.info('Using label smooth: {}'.format(opt.use_smooth_label))\n",
    "    logger.info('lr_scheduler: {}'.format(opt.lr_scheduler))\n",
    "    logger.info('Using the GPU: {}'.format(str(opt.gpu_id)))\n",
    "\n",
    "    model  = make_model('{}'.format('xception'), num_classes=2,\n",
    "                        pretrained=True)\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-4 ,weight_decay=5e-4)\n",
    "    #lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2, eta_min=1e-6, last_epoch=-1)\n",
    "    train_model(model, criterion, optimizer,\n",
    "              lr_scheduler=lr_scheduler)\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:39:28.591524Z",
     "iopub.status.busy": "2021-05-30T17:39:28.590913Z",
     "iopub.status.idle": "2021-05-30T17:40:13.055831Z",
     "shell.execute_reply": "2021-05-30T17:40:13.053379Z",
     "shell.execute_reply.started": "2021-05-30T17:39:28.591461Z"
    }
   },
   "outputs": [],
   "source": [
    "submit=pd.read_csv('../input/fu-data/data/result.csv',header=None)\n",
    "submit.columns=['name']\n",
    "model  = make_model('{}'.format('xception'), num_classes=2,\n",
    "                        pretrained=False)\n",
    "net_weight='./ckpt/xception/xception_20.pth'\n",
    "model.load_state_dict(torch.load(net_weight))\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "#\n",
    "infer_transforms=T.Compose([\n",
    "                T.Resize((opt.input_size,opt.input_size)),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "                T.RandomVerticalFlip(p=0.25),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "            ])\n",
    "result=[]\n",
    "test_dir='../input/fu-data/data/test/'\n",
    "for name in submit['name'].values:\n",
    "    img_path=os.path.join(test_dir,name)\n",
    "    data = Image.open(img_path)\n",
    "    data = data.convert('RGB')\n",
    "    data = infer_transforms(data)\n",
    "    data=data.unsqueeze(0)\n",
    "    inputs= data.cuda()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    result.append(preds.cpu().data.numpy()[0])\n",
    "    #\n",
    "submit['label']=result\n",
    "submit.to_csv('submit.csv',index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T17:40:13.059582Z",
     "iopub.status.busy": "2021-05-30T17:40:13.059121Z",
     "iopub.status.idle": "2021-05-30T17:40:13.082244Z",
     "shell.execute_reply": "2021-05-30T17:40:13.081525Z",
     "shell.execute_reply.started": "2021-05-30T17:40:13.059527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eao40.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bihq9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ay5mr.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k6zri.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baqtd.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>9up1r.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>dsu37.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>8bv4d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>d62ki.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>jolf9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  label\n",
       "0    eao40.png      1\n",
       "1    bihq9.png      0\n",
       "2    ay5mr.png      1\n",
       "3    k6zri.png      0\n",
       "4    baqtd.png      0\n",
       "..         ...    ...\n",
       "304  9up1r.png      1\n",
       "305  dsu37.png      1\n",
       "306  8bv4d.png      0\n",
       "307  d62ki.png      1\n",
       "308  jolf9.png      1\n",
       "\n",
       "[309 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
